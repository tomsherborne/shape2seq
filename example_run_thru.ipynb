{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seq2seq example run through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SRC from [higepon](https://gist.github.com/higepon/eb81ba0f6663a57ff1908442ce753084) to get to grips with the API.\n",
    "* TF guide for NMT [here](https://www.tensorflow.org/tutorials/seq2seq)\n",
    "* Documentation [here](https://www.tensorflow.org/api_guides/python/contrib.seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/miniconda3/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "seq2seq = tf.contrib.seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup\n",
    "hparams = tf.contrib.training.HParams(batch_size=3,\n",
    "                                      encoder_length=4,\n",
    "                                      decoder_length=5,\n",
    "                                      num_units=6,\n",
    "                                      src_vocab_size=7,\n",
    "                                      tgt_vocab_size=9,\n",
    "                                      embedding_size=8,\n",
    "                                      optimizer=\"Adam\",\n",
    "                                      learning_rate=0.01,\n",
    "                                      max_gradient_norm=5.0,\n",
    "                                      beam_width=9,\n",
    "                                      use_attention=False,\n",
    "                                     )\n",
    "\n",
    "# Symbol for starting to decode\n",
    "tgt_sos_id = 7\n",
    "\n",
    "# Symbol for end of decode process\n",
    "tgt_eos_id = 8\n",
    "\n",
    "# Refresh graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Variable initialiser\n",
    "initializer = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder input placeholder is time major [enc_len, batch_size]\n",
    "enc_inputs = tf.placeholder(dtype=tf.int32, shape=(hparams.encoder_length, hparams.batch_size), name=\"enc_input\")\n",
    "\n",
    "# Encoder embedding matrix [can be initialised with GloVe] [src_vocab_size, embedding_size]\n",
    "enc_embeddings = tf.get_variable(shape=(hparams.src_vocab_size, hparams.embedding_size), name=\"enc_embed\")\n",
    "\n",
    "# Lookup enc_input in the embedding matrix [enc_len, batch_size, embedding_size]\n",
    "enc_input_embs = tf.nn.embedding_lookup(params=enc_embeddings, ids=enc_inputs)\n",
    "\n",
    "# LSTM encoder\n",
    "lstm_encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hparams.num_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM Computation graph for Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Dynamic RNN: outputs [enc_len, batch_size, num_units]: enc_state [batch_size, num_units]\n",
    "encoder_outputs, encoder_state = tf.nn.dynamic_rnn(cell=lstm_encoder_cell, \n",
    "                                                   inputs=enc_input_embs, \n",
    "                                                   time_major=True,\n",
    "                                                   dtype=tf.float32\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder input placeholder is time major [dec_len, batch_size]\n",
    "# Decoder lengths [batch_size]\n",
    "\n",
    "# For training we use 100% teacher forcing so each time step uses Ground Truth inputs. Inference is 100% free running\n",
    "dec_inputs = tf.placeholder(dtype=tf.int32, shape=(hparams.decoder_length, hparams.batch_size),name=\"dec_inputs\")\n",
    "dec_lens = tf.placeholder(dtype=tf.int32, shape=(hparams.batch_size), name=\"dec_len\")\n",
    "\n",
    "# Decoder embedding matrix [can be initialised with GloVe] [tgt_vocab_size, embedding_size]\n",
    "dec_embeddings = tf.get_variable(shape=(hparams.tgt_vocab_size, hparams.embedding_size), name=\"dec_embed\")\n",
    "\n",
    "# Lookup dec_inputs \n",
    "dec_input_embs = tf.nn.embedding_lookup(params=dec_embeddings, ids=dec_inputs)\n",
    "\n",
    "# LSTM decoder\n",
    "lstm_decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hparams.num_units)\n",
    "\n",
    "# Projection layer between LSTM outputs and vocab size for softmax learning model\n",
    "projection_layer = tf.layers.Dense(units=hparams.tgt_vocab_size, activation=None, kernel_initializer=initializer, use_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### seq2seq decoding declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare decoding helper\n",
    "dec_helper = seq2seq.TrainingHelper(inputs=dec_input_embs, sequence_length=dec_lens, time_major=True, name=\"dec_helper\")\n",
    "\n",
    "if hparams.use_attention:\n",
    "    # Attention states are batch major [batch_size, max_time, num_units]\n",
    "    attention_states = tf.transpose(encoder_outpus, [1, 0, 2])\n",
    "\n",
    "    luong_attn_mechanism = seq2seq.LuongAttention(num_units=hparams.num_units, \n",
    "                                                 memory=attention_states, \n",
    "                                                 memory_sequence_length=None\n",
    "                                                 )\n",
    "\n",
    "    decoder_cell = seq2seq.AttentionWrapper(cell=lstm_decoder_cell,\n",
    "                                            attention_mechanism=luong_attn_mechanism,\n",
    "                                            attention_layer_size=hparams.num_units\n",
    "                                            )\n",
    "\n",
    "    dec_initial_state = lstm_decoder_cell.zero_state(hparams.batch_size, tf.float32).clone(cell_state=encoder_state)\n",
    "else:\n",
    "    # Decoding with dec_helper when encoder output feeds to decoder input\n",
    "    dec_initial_state = encoder_state\n",
    "\n",
    "decoder = seq2seq.BasicDecoder(cell=lstm_decoder_cell,\n",
    "                               helper=dec_helper,\n",
    "                               initial_state=dec_initial_state,\n",
    "                               output_layer=projection_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM Computation graph for Decoding with seq2seq helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2s version of decoding\n",
    "# final_outputs.rnn_output : RNN states [batch_size, dec_len, tgt_vocab_size]\n",
    "# final_outputs.sample_id  : Argmax for IDs from RNN outputs [batch_size, dec_len]\n",
    "# final_state              : Final RNN states [batch_size, num_units]\n",
    "# final_seq_lens           : Decoded sequences [batch_size, dec_len]\n",
    "\n",
    "final_outputs, _final_state, _final_seq_lens = seq2seq.dynamic_decode(decoder)\n",
    "\n",
    "output_logits = final_outputs.rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_output.shape= (3, ?, 9)\n",
      "sample_id.shape= (3, ?)\n",
      "final_state= LSTMStateTuple(c=<tf.Tensor 'decoder/while/Exit_3:0' shape=(3, 6) dtype=float32>, h=<tf.Tensor 'decoder/while/Exit_4:0' shape=(3, 6) dtype=float32>)\n",
      "final_sequence_lengths.shape= (3,)\n"
     ]
    }
   ],
   "source": [
    "print(\"rnn_output.shape=\", final_outputs.rnn_output.shape)\n",
    "print(\"sample_id.shape=\", final_outputs.sample_id.shape)\n",
    "print(\"final_state=\", _final_state)\n",
    "print(\"final_sequence_lengths.shape=\", _final_seq_lens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup loss and training operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training targets for decoder [batch_size, dec_len]\n",
    "dec_targets = tf.placeholder(dtype=tf.int32, shape=(hparams.batch_size, hparams.decoder_length))\n",
    "\n",
    "# Setup loss computation [could also use seq2seq.sequence_loss]: https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss\n",
    "smxe_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dec_targets,\n",
    "                                                           logits=output_logits,\n",
    "                                                           name=\"smxe_loss\")\n",
    "\n",
    "# Reduce loss in batch by mean\n",
    "loss_ = tf.reduce_mean(smxe_loss)\n",
    "\n",
    "# Training operations\n",
    "global_step = tf.Variable(initial_value=0, \n",
    "                          name=\"global_step\", \n",
    "                          trainable=False, \n",
    "                          collections=[tf.GraphKeys.GLOBAL_STEP,\n",
    "                                       tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "                         )\n",
    "\n",
    "train_op = tf.contrib.layers.optimize_loss(loss=loss_,\n",
    "                                           global_step=global_step,\n",
    "                                           learning_rate=hparams.learning_rate,\n",
    "                                           optimizer=hparams.optimizer,\n",
    "                                           clip_gradients=hparams.max_gradient_norm,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF Interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets\n",
      "[[1 0 1]\n",
      " [2 5 2]\n",
      " [3 6 3]\n",
      " [4 3 4]]\n"
     ]
    }
   ],
   "source": [
    "# Encoder \n",
    "\n",
    "tweet1 = np.array([1, 2, 3, 4])\n",
    "tweet2 = np.array([0, 5, 6, 3])\n",
    "\n",
    "# Make batch data [TIME MAJOR]\n",
    "train_encoder_inputs = np.stack((tweet1, tweet2, tweet1), axis=0).astype(np.int32).T\n",
    "\n",
    "print(\"Tweets\")\n",
    "print(train_encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replies\n",
      "[[2 3 4 5 8]\n",
      " [2 3 4 5 8]\n",
      " [2 3 4 5 8]]\n",
      "Inputs\n",
      "[[7 7 7]\n",
      " [2 5 2]\n",
      " [3 6 3]\n",
      " [4 4 4]\n",
      " [5 3 5]]\n",
      "Decoder lengths\n",
      "[5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "\n",
    "training_decoder_input1 = [tgt_sos_id, 2, 3, 4, 5]\n",
    "training_decoder_input2 = [tgt_sos_id, 5, 6, 4, 3]\n",
    "\n",
    "training_target_label1 = [2, 3, 4, 5, tgt_eos_id]\n",
    "training_target_label2 = [5, 6, 4, 3, tgt_eos_id]\n",
    "\n",
    "training_target_labels = np.stack((training_target_label1, \n",
    "                                    training_target_label1, \n",
    "                                    training_target_label1), axis=0).astype(np.int32)\n",
    "print(\"Replies\")\n",
    "print(training_target_labels)\n",
    "\n",
    "training_decoder_inputs = np.stack((training_decoder_input1, \n",
    "                                    training_decoder_input2, \n",
    "                                    training_decoder_input1), axis=0).astype(np.int32).T\n",
    "print(\"Inputs\")\n",
    "print(training_decoder_inputs)\n",
    "\n",
    "training_decoder_lens = np.ones((hparams.batch_size), dtype=int) * hparams.decoder_length\n",
    "\n",
    "print(\"Decoder lengths\")\n",
    "print(training_decoder_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18588\n",
      "2.15841\n",
      "2.1305\n",
      "2.10127\n",
      "2.07033\n",
      "2.03751\n",
      "2.0029\n",
      "1.96689\n",
      "1.93016\n",
      "1.89365\n",
      "1.85838\n",
      "1.82512\n",
      "1.79429\n",
      "1.76578\n",
      "1.73917\n",
      "1.71383\n",
      "1.68912\n",
      "1.66458\n",
      "1.63994\n",
      "1.61514\n",
      "1.59027\n",
      "1.56549\n",
      "1.54099\n",
      "1.5169\n",
      "1.49332\n",
      "1.47027\n",
      "1.44781\n",
      "1.42595\n",
      "1.40439\n",
      "1.38238\n",
      "1.35925\n",
      "1.33508\n",
      "1.31048\n",
      "1.28596\n",
      "1.26154\n",
      "1.23677\n",
      "1.21112\n",
      "1.18444\n",
      "1.15707\n",
      "1.12972\n",
      "1.10279\n",
      "1.07593\n",
      "1.04861\n",
      "1.02121\n",
      "0.99462\n",
      "0.969204\n",
      "0.944472\n",
      "0.919904\n",
      "0.89562\n",
      "0.872007\n",
      "0.848958\n",
      "0.826036\n",
      "0.80322\n",
      "0.780929\n",
      "0.759335\n",
      "0.7382\n",
      "0.717399\n",
      "0.697144\n",
      "0.677581\n",
      "0.658512\n",
      "0.639726\n",
      "0.621262\n",
      "0.603187\n",
      "0.585408\n",
      "0.56782\n",
      "0.550452\n",
      "0.53339\n",
      "0.516663\n",
      "0.500262\n",
      "0.484205\n",
      "0.468542\n",
      "0.453319\n",
      "0.438556\n",
      "0.424261\n",
      "0.410443\n",
      "0.39711\n",
      "0.384264\n",
      "0.371897\n",
      "0.359994\n",
      "0.348538\n",
      "0.337523\n",
      "0.326941\n",
      "0.31679\n",
      "0.307058\n",
      "0.297733\n",
      "0.288793\n",
      "0.280216\n",
      "0.271974\n",
      "0.264041\n",
      "0.256389\n",
      "0.248993\n",
      "0.241834\n",
      "0.234896\n",
      "0.228166\n",
      "0.221638\n",
      "0.215306\n",
      "0.209168\n",
      "0.203224\n",
      "0.197475\n",
      "0.191924\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    _, loss_val = sess.run(fetches=[train_op, loss_],\n",
    "                           feed_dict={\n",
    "                               enc_inputs: train_encoder_inputs,\n",
    "                               dec_targets: training_target_labels,\n",
    "                               dec_inputs: training_decoder_inputs,\n",
    "                               dec_lens: training_decoder_lens\n",
    "                           })\n",
    "    print(loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model is now trained, test with inference on toy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference helper. Similar to training helper but free running over teacher forcing\n",
    "tiled_sos_id = tf.fill([hparams.batch_size], tgt_sos_id)\n",
    "\n",
    "inference_helper = seq2seq.GreedyEmbeddingHelper(embedding=dec_embeddings,\n",
    "                                                 start_tokens=tiled_sos_id,\n",
    "                                                 end_token=tgt_eos_id)\n",
    "\n",
    "# Inference Decoder runs the decoding process with free running inputs\n",
    "inference_decoder = seq2seq.BasicDecoder(cell=lstm_decoder_cell,\n",
    "                                         helper=inference_helper,\n",
    "                                         initial_state=dec_initial_state,\n",
    "                                         output_layer=projection_layer)\n",
    "\n",
    "# Limit realistic RNN length\n",
    "maxit = tf.round(tf.reduce_max(hparams.encoder_length) * 2)\n",
    "\n",
    "outputs, _, _ = seq2seq.dynamic_decode(inference_decoder, maximum_iterations=maxit)\n",
    "translations = outputs.sample_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tweets\n",
    "inference_encoder_inputs = train_encoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2, 3, 4, 5, 8],\n",
      "       [2, 3, 4, 5, 8],\n",
      "       [2, 3, 4, 5, 8]], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "replies = sess.run(fetches=[translations], \n",
    "                   feed_dict={\n",
    "                       enc_inputs: inference_encoder_inputs\n",
    "                   })\n",
    "\n",
    "print(replies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Well thats only 66% correct, lets try a Beam search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam Search\n",
    "# Replicate encoder infos beam_width times\n",
    "decoder_initial_state = tf.contrib.seq2seq.tile_batch(\n",
    "    dec_initial_state, multiplier=hparams.beam_width)\n",
    "\n",
    "# Define a beam-search decoder\n",
    "inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "        cell=lstm_decoder_cell,\n",
    "        embedding=dec_embeddings,\n",
    "        start_tokens=tf.fill([hparams.batch_size], tgt_sos_id),\n",
    "        end_token=tgt_eos_id,\n",
    "        initial_state=decoder_initial_state,\n",
    "        beam_width=hparams.beam_width,\n",
    "        output_layer=projection_layer,\n",
    "        length_penalty_weight=0.0)\n",
    "\n",
    "# Dynamic decoding\n",
    "outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "    inference_decoder, maximum_iterations=maxit)\n",
    "\n",
    "# Convert to [batch_siz]\n",
    "translations = tf.transpose(outputs.predicted_ids,[0, 2, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2 3 2 2 2 2 2 2 2]\n",
      "  [3 4 2 3 3 8 3 3 3]\n",
      "  [4 5 3 4 8 8 4 3 4]\n",
      "  [5 8 4 8 8 8 5 4 5]\n",
      "  [8 8 5 8 8 8 5 5 3]\n",
      "  [8 8 8 8 8 8 8 8 8]]\n",
      "\n",
      " [[2 3 2 2 2 2 2 2 2]\n",
      "  [3 4 2 3 3 8 3 3 3]\n",
      "  [4 5 3 4 8 8 4 3 4]\n",
      "  [5 8 4 8 8 8 5 4 5]\n",
      "  [8 8 5 8 8 8 5 5 3]\n",
      "  [8 8 8 8 8 8 8 8 8]]\n",
      "\n",
      " [[2 3 2 2 2 2 2 2 2]\n",
      "  [3 4 2 3 3 8 3 3 3]\n",
      "  [4 5 3 4 8 8 4 3 4]\n",
      "  [5 8 4 8 8 8 5 4 5]\n",
      "  [8 8 5 8 8 8 5 5 3]\n",
      "  [8 8 8 8 8 8 8 8 8]]]\n"
     ]
    }
   ],
   "source": [
    "replies = sess.run(translations, feed_dict={\n",
    "                       enc_inputs inference_encoder_inputs,\n",
    "                       dec_lens: training_decoder_lens\n",
    "                   })\n",
    "print(replies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(replies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(replies[0], [0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies[0].beam_search_decoder_output._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
